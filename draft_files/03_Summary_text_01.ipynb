{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast, pipeline, AutoTokenizer,T5Tokenizer, T5ForConditionalGeneration\n",
    "import os\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the text_generated\n",
    "folder_path = 'processed_data'\n",
    "file_path = os.path.join(folder_path, 'pdf_text.txt')\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    full_text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - facebook/mbart-large-50-many-to-many-mmt (Multilingual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class MultilingualSummarizer:\n",
    "    def __init__(self, model_name='facebook/mbart-large-50-many-to-many-mmt'):\n",
    "        self.tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
    "        self.model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    def summarize(self, text, source_lang='es_XX', target_lang='es_XX', max_length=512, num_beams=5, length_penalty=1.5, no_repeat_ngram_size=2):\n",
    "        self.tokenizer.src_lang = source_lang\n",
    "        forced_bos_token_id = self.tokenizer.lang_code_to_id[target_lang]\n",
    "\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "        summary_ids = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            forced_bos_token_id=forced_bos_token_id,\n",
    "            num_beams=num_beams,\n",
    "            length_penalty=length_penalty,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            early_stopping=False\n",
    "        )\n",
    "\n",
    "        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "\n",
    "#def preprocess_text(text):\n",
    "    # Remove irrelevant mentions and other noise\n",
    "    #clean_text = re.sub(r'\\[Música\\].*?Compartir', '', text, flags=re.DOTALL).strip()\n",
    "    # Ensure consistent punctuation and spacing\n",
    "   #clean_text = re.sub(r'\\s+', ' ', clean_text)  # Replace multiple spaces with a single space\n",
    "    #return clean_text\n",
    "\n",
    "def split_text(text, max_length):\n",
    "    sentences = text.split('. ')  # Use period as delimiter\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) + 1 > max_length:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = sentence\n",
    "        else:\n",
    "            current_chunk += ('. ' if current_chunk else '') + sentence\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "    return chunks\n",
    "\n",
    "def summarize_text(text, summarizer, max_length=512, chunk_size=1024):\n",
    "    chunks = split_text(text, chunk_size)\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarizer.summarize(chunk, max_length=max_length)\n",
    "        summaries.append(summary)\n",
    "    return ' '.join(summaries)\n",
    "\n",
    "# Usage in the code\n",
    "summarizer = MultilingualSummarizer()\n",
    "#input_text = preprocess_text(full_text)\n",
    "summarized_text = summarize_text(full_text, summarizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "En este contexto, el Gobierno de la República Islámica del Irán (República de Corea) ha adoptado una serie de medidas encaminadas a combatir el racismo, la discriminación racial y las formas conexas de intolerancia, entre otras cosas, mediante la adopción de un plan de acción nacional para luchar contra la trata de personas y la promoción de los derechos de las personas con discapacidades. Introducción. La meditación Zen se llama zazen, za: sentarse, zen: concentration The purpose of this manual is to expand, complement and help in the memory of the explanations that are given during the initiation session, but in any case do not replace this. You need to see people sitting in a posture of Zazen and we help you with your posturing. Para hacer zazen correctamente se deben hacer simultáneamente tres cosas: (i) Dejar pasar los pensamientos. (ii) Hacer la respiración zen. [iii] Mantener la postura exacta de Zazen durante todo el tiempo que dura el zasen. 1.1.- La postura de zazan. En la primera sesión, el balance de la pel es superior a la quinta vertebra lumbar, lo que es más importante es que las rodillas se pongan en el suelo. En esta sesión de iniciación, los balances del pel son inferior a los que se ponen en la segunda sesión y, por lo tanto, la postura de esta mañana no es tan importante como la de hoy, sino que la posición de este mañana se mantendrá durante todo el tiempo que dura la zazen, pero que no llegue a conseguirla, porque se está haciendo el trabajo de “atar la mente a un poste” Lo que te queremos decir es, con la peor postura, puedes tener una buena zazan, o sea, no te desanimas si tienes dificultades con las piernas o tu postura es desgarrada al principio. Echas estas aclaraciones ahora vemos el postura por siglos trasmitida. En este punto, el iniciador debe prestar especial atención al principio, porque no es un movimiento normal y parece que uno está forzado, con la práctica se llega a ser muy confortable en esta postura. Esta posición de la lengua es muy común en las prácticas que trabajan la energía corporal, la razón es que termina un circuito energético: la microcosmic orbit. Los ojos permanecen semiabiertos. En zazen no se cierran nunca los ojos, ya que entraría en un estado mental de somnolencia. La vista se posa sobre el suelo a un metro de distancia. Tu vista no mira a ese punto, el punto solo sirve de referencia para marcar la dirección de tus ojos. Esta vista tiene una visión de 180 degrees, si algo se movie en el extremo de tu izquierda o derecha lo vería aunque no estás mirando en esas direcciones. Para hacer el mudra se pone el palmo de la mano izquierda sobre el palma del mano derecha, ambos horizontales y pegas el canto de las manos junto al vientre debajo del ombligo. Los dedos pulgares tocan en su extremo y permanecen horizontale formando una línea recta. En el Mudra debe prestar atención a que los dedo pulgaras no forman ni valle ni montaña. Se llama valle cuando estos demos apuntan al suelo y indican que se ha entrado en somnolencia. En este punto de contacto puede sentirse como una especie de vibración, una mini corriente, es la energía que sube al cerrar el circuito energético que conforman tronco, arms y mudra. Esta es la respiración normal. Imaginamos ahora que con el globo hincha por el cuello del globo y empuñando hacia abajo, el aire descende y los globos hinchan un poco más. En el respirado Zen hay que hacer que en la exhalación el diafragma trabaje como el piston empujando el air hacia arriba, hacía los intestines. Es por eso que el viento hinza un pouco, aunque estés exhalando. En general, no tenemos control consciente del movimiento del diafragma. No te preocupes, aprender el respiración Zen con la práctica. Para ejecutar el breath Zen lo primero que tenemos que decir es que este respirado natural brota de una postura correcta. Es por eso que es muy importante balance la pelvis a nivel de la quinta verdabra lumbar para liberar el diabrum. En el momento de la meditación, la respiración se prolonga, y sobre esto queda por añadir que debe procurar que su respiracion sea muy silenciosa para no perturbar el zazen de los demás. Si tiene una práctica regular, el Zazen crecerá junto con tu zazan de forma natural, inconsciente y automática. Si tiene un mal momento de dolor de piernas hacer este conteo de respiraciones te ayudará. Si tienes interés te recomendamos que ejecute la respiración zen en momentos perdidos. En poco tiempo te descubriré a ti mismo haciendo esta respiracion en algún moment de tu vida de forma inconsciente. La respiration zen es buena, el cuerpo lo sabe y busca en forma natural. Para probarla, por ejemplo, en el metro, de pie y agarrado a la barra, ejecutas y los comptes. Se trata de familiarizarte con ella, que tu cuerpo se acostumbre a ejecutarla. En el dojo, at the end of zazen, sing the sutras. It’s a great way to execute la respiración Zen. You have to sing extending the expiración hasta vaciarte de todo el aire. En el momento de la meditación, no hay que pensar en eso, sino en lo que es, y no se puede imaginar. En el párrafo 1 de la parte dispositiva se dice lo siguiente: “Las Naciones Unidas están dispuestas a ayudar a los Estados Miembros a cumplir sus obligaciones en virtud de las resoluciones pertinentes del Consejo de Seguridad, incluida la resolución 1244 (1999), de conformidad con lo dispuesto en el derecho internacional, a fin de garantizar la protección de los civiles en los conflictos armados, incluidos los refugiados, los desplazados internos y los trabajadores migratorios”. En los primeros minutos de zazen, y sobre todo en el principiante, hay una riada de pensamientos con las cosas de su día a día que van y vienen. El practicante se concentra en la postura, la respiración y en dejar pasar los thoughts. La oleada de pensamentos comenzará a disminuir, ira cesa y finalmente se detene. Aquí has llegado el estado de Concentración, antes estaba en los estados de observación. Si el pensamiento surge desaparece inmediatamente será una observación relámpaga, instantánea y sigue estando en el Estado de Concentración. En el estado de observación se utiliza la Concentración y en el Estado de Concentración la Observación. Ambos aspectos, Con concentración Shi y Observation Kan, asociados dan la actitud correcta durante zazen. Producidos simultáneamente give la expresión más alta y ideal de la conciencia Hishiryo, esta conciencia es la que buscamos en Zazen y se describe en la sección 4. En zasen debe ir alternando según las necesidades del estado of observaciones al de concentraciones y viceversa. 2.2.- Kontin y Sanran. Kontins y sanran son los dos enemigos de za zen. En Zasen ni kontin ni sanrán. Sanra Sanr is la mente errante, soñara y pensativa.Sanran nace a partir del continuo movimiento de pensamientos.To tratarlo, se usa la concentration y te concentra en tener la postura correcta, respirar y dejar pasar thoughts hasta que cese el sanra. Si pase un tiempo empleando la Concentración, y a pesar de esto el sanran no cesa, puede probar a emplear la Observación y observar objetivamente los pensamientos que surgen. Simultáneamente puede poner la mente en contacto entre los pulgares o en la imaginaria linea vertical que va del ombligo a la nariz y tendrán también la sensación de su respiración. Kontin. Contain es la somnolencia. Es un zazen muy incómodo porque la sononcia se está apoderando de ti y te durmas. Los ojos tend a cerrar, no debe dejarlos cerrar en ningún momento porque te dumas seguro. Si, despite esto, el kontin continua y siente que durme, puede probar a emplear la Concentración pese a estar en el estado de Concentración, y pone la concentración en mantener la postura correcta y ejecutar la respiración zen. En el caso de los Estados Unidos de América, el Presidente de la Corte Suprema de Justicia y el Fiscal General de las Naciones Unidas, en su calidad de Presidente del Tribunal Supremo, es el único que ha sido elegido para ocuparse de esta cuestión, a saber, la cuestión de si el Tribunal Superior tiene jurisdicción sobre los asuntos relativos a los derechos humanos y las libertades fundamentales, o si, al mismo tiempo, está facultado para dictar sentencias sobre las cuestiones relativas al derecho a la libertad de opinión y de expresión (artículo 2 del Pacto Internacional de Derechos Económicos, Sociales y Culturales) (párrafo 1 del artículo 3 del Convenio de Ginebra sobre la protección de todas las personas contra las desapariciones forzadas, párrafos 3 y 4 del Protocolo de La Haya sobre el Derecho al Desarrollo), es decir, que el Consejo de Ministros de Relaciones Exteriores del Reino Unido tiene la facultad de pronunciar una sentencia sobre todos los casos de desaparición forzada, y, por consiguiente, no puede pronunciarse sobre esos casos a menos de dos horas antes de que se adopten las medidas necesarias para resolver los conflictos internos. En la misma sesión, el Presidente de la Conferencia de las Partes en el Tratado sobre la no proliferación de los sistemas de armas nucleares (TNP) presentó el proyecto de resolución A/C.1/55/L.19, titulado “Convención sobre las Armas Químicas” (Tratado de Ginebra de 1995) (véase el párrafo 1 del documento TNP/CONF.1995/CRP.1, párr. En la sesión de iniciación te indicaremos una serie de reglas que están encaminadas a conseguir la adecuada concentración en el practicante. Es muy importante que llegue al dojo diez minutos antes del inicio para que te dé tiempo a cambiar de ropa y sentarte en zazen. 3.2.- Kin Hin. Kin hin es andar con la respiración. Se hace de pie con el objetivo de que las piernas, el resto del cuerpo y la mente recuperen para el siguiente zazan. You have que hacerlo sin perder la concentración que has mantenido durante el anterior zajen. Para hacer kin hin te colocas de pie con los pies juntos. Con la mano izquierda incierra el dedo pulgar de esa mano y poñe este puño junto al esternón con el brazo horizontal. La mano derecha abarca este Puño con la braza horizontal. De cintura para arriba el cuerpo es igual que en zazen: balance la pelvis, recta espalda, meter el mentón, tongue al paladar, vista de 180 degrees posada sobre la cintur del que va en frente a ti en la fila de kin Hin. Kin hin begins adelantando el pie derecho medio paso. Se pasa todo el peso del cuerpo a esa pier. Es importante que el corva de la rodilla este muy bien estrado para que se recuperen las piernas. El pie de atrás está apoyado para mantener el equilibrio, pero no soporta ningún peso. Una zona de concentración es la zona donde el dedo gordo se une al pie. La presión de esta zona contra el suelo provoca en el rodilla un giro de sentido contrario a lo que tiene durante zazen, y contribuye a recuperarla. En la explicación de kin hin hemos hablado de adelantar el pie medio paso, este es un medio paso muy pequeño, si hace más largo tendrá que inclinar mucho para pasar su peso al pie de delante. En este zazen también se canta el sutra del kesa, son cuatro líneas que hay en otro papel distinto. Este Sutra es cantado sentado en Zazen y antes de que termine éste. If you are interested en leer los sutras en castellano o incluso estudiarlos pregunta al kyosaku y él te orientará. 3.4.- El kyosaku. Hasta ahora hemos hablado del kyosoku como la persona responsable del dojo en ausencia de la maestra. Kyosak es también como llamamos a un bastón de madera que está en el altar. El kyosaku es un ejercicio que se realiza en el corazón de la humanidad, en la parte inferior del cuerpo, a través del corazón y el cuerpo de los seres humanos, y que tiene por objeto ayudar a las personas que viven con el kyusaku a hacerse sentir más alentadas y a sentirse más satisfechas con la vida de cada persona que vive en un mundo en que está viviendo. En Zazen, you’ll hear the “kyosakuman”, the small ritual that he does to pick up the kyosaku of the altar, and you will immediately hear los golpes del kyosoku sobre los hombros de los practicantes que lo solicitan. Espera que el kyosakus pase a ti y ponga las manos en gasho. Cuando el Kyosuku te vea, will gently tocarte en el hombra para que sepa que es tu turno. El Zazen de la mañana comienza a 7 y termina a 8:30, es ese momento puede abandonar el dojo. Si lo deseas puede participar en el güen mai. No obstante, we understand que los horarios para hacer zazen del dojo pueden no ser compatibles con tu vida profesional y familiar, y hay personas que no disponen del tiempo necesario para acudir al doje con alguna regularidad. En este sentido, el aguantar el dolor en ti cimentará un zazen fuerte y actuará en dos direcciones: aumentar tu tolerancia al dolor y habituar tus piernas al tiempo de Zazen. La mejor hora es por la mañana al levantarse y antes de ir a tus ocupaciones. En el Zen no hay heroes, si notas que ha superado su nivel de tolerancia al dolor, hace gasho, cambia la pierna que estaba arriba por la de abajo, if estás en medio loto. En la actualidad, la mayoría de las personas que viven con el VIH/SIDA no tienen acceso a los servicios de atención de la salud, ni a la atención médica, sino que se encuentran en una situación de inseguridad alimentaria y de desempleo, en particular en las zonas rurales y urbanas, donde la prevalencia de enfermedades de transmisión sexual es más alta que la de los países en desarrollo (véase el párrafo 1 del artículo 2 del Pacto Internacional de Derechos Económicos y Sociales (A/CONF.189/PC.1/Rev.1, párr. Lamentablemente, la psicología aún no conoce el pensamiento Hishiryo y no podemos dar un equivalente como dimos para el pensamento Fushiry. La ciencia no lo conoce, pero el practicante de zazen si porque experimenta directamente. Con el fin de que los hombres y las mujeres desempeñen un papel más importante en la vida de la humanidad, la comunidad internacional debe hacer todo lo posible para que el hombre y la mujer participen en el proceso de adopción de decisiones sobre el futuro de las Naciones Unidas, en particular en lo que se refiere a los derechos humanos y a la igualdad entre los géneros, y en este sentido, el Consejo de Derechos Humanos debe tener en cuenta las recomendaciones del Secretario General sobre la cuestión de los niños y los conflictos armados (E/CN.4/Sub.2/2004/L.2). Cuando nacemos Mana está totalmente vacía y se desarrolla con el transcurso de nuestra vida formando nuestro Ego. Sin embargo, Alaya trae unas semillas genéticas que dan origen a nuestra personalidad. En efecto, cuando Mana tiene, por ejemplo: un problema que quiere resolver, Mana baja una semilla a Araya donde subconscientemente este problema va a resolver y cuando este germinada subirá la solución a Mana donde se hará consciente. En el siglo IX, los maestros chinos fueron capaces de desarrollar una teoría que coincide con lo que dice la psicología moderna, cuando todavía faltan muchos siglos para el nacimiento de Freud? La respuesta es simple: Pasaban todo el día en su templo haciendo zazen y esto les dio un conocimiento exacto de cómo funciona la mente y el pensamiento. La conciencia Amala es la que contiene el pensamento Hishiryo. El derecho es la base de las funciones intelectuales y verbales junto con los deseos, la volición... The right is responsible for the emotional and non verbal aspects. Podemos decir que por el hemisferio nos conectamos con la naturaleza y por la izquierda a la sociedad. Para el equilibrio del individuo es importante que la interacción entre ambos cerebros sea suave, sin predominar un cerebro sobre otro. En el hombre primitivo prevalecía el derecho sobre el left, ya que este hombre vivía inmerso en la natureza. En la práctica de zazen, el hemisferio izquierdo se anula por no pensar y se potencia el derecho a hacer que el cuerpo esté manteniendo la postura. En la práctica, la técnica de psicoanálisis trata de hacer conscientes los elementos de psiquismo inconsciente. En general, Zazen actúa como una terapia que produce una profunda relajación de los sistemas neurovegetivos, dando otra percepción del mundo que provoca no sólo una sensación de bienestar, de estar más feliz en su vida, sino también a cambio hacía una forma de vida que vienen llevando. En el caso de los monjes, el electroencefalograma se produce a ritmo más lento y regular, lo que significa que el monje no puede estar al día y que no tiene la posibilidad de salir de la cama. Los monjes en los que aparecieron las ondas Theta sobre su estado mental y describíanlo como de profunda calma y bienestar. La meditación es una forma de vida que se lleva a cabo hoy en día conlleva a estrés a muchas personas y estas técnicas ayudan a encontrar un equilibrio. Zazen es no una meditacion en este sentido. 5.2.- Mushotoku. Sikantanza. People interested en meditar y acercarse al Zen tienen un objetivo. Esto es totalmente natural y lógico. Este objetivo puede ser alcanzar la iluminación, el Nirvana, que en el Zen se llama Satori. La mayoría busca un bienestar como el que comentamos en la anterior sección. Otros buscan la autoconocimiento y con ello superar phobias, traumas y todo tipo de bloqueos personales... También están los que buscan el crecimiento interior... son muchos los objetivos, tanto como personas. Pero con zazen no tienes que tener ningún objetivo En el momento de la inauguración, el jefe de las fuerzas armadas de los Estados Unidos de América (Movimiento de Liberación del Sudán) hizo un llamamiento a la comunidad internacional para que apoyase al Gobierno de Transición de Timor-Leste (Puntlandia) y a las Naciones Unidas (Estados Federados de Yugoslavia) en la lucha contra la impunidad y los crímenes de lesa humanidad, así como a los organismos especializados (ACNUR, UNICEF, ONUSIDA, UNFPA, UNODC, PNUD, ONU-Hábitat, etc.) a fin de que los gobiernos y las organizaciones no gubernamentales de todo el mundo participen activamente en el proceso de consolidación del estado de derecho. En el siglo VI Bodhidarma, una persona mítica en la historia del Zen, llevó este budismo a China, donde se mezcló con el pensamiento reinante en China en esa época: Lao Tse, Confucio y el Taoísmo. Y de este coctel genial nació el Zen. En China el zen fue protegido por los emperadores y tuvo un gran auge. Se crearon cinco escuelas, de las cuales sólo pertenezcan al Zen Soto y a Zen Rinzai. En el siglo XIII Dogen viajó de Japón a China en busca del verdadero Zen. A su vuelta sentó las bases del Zen Soto japonés en el Shobogenzo, que es el texto de referencia en nuestra escuela. Deshimaru nació en Paris in the late 1960s, founding a dojo y un templo, y con él nacido el Zen europeo. Su legado se extendió muy rápido llegando a todos los países de Europa y Sudamérica. Nuestra maestra Barbara Kosen estudió en París con el maestro De Shimaro hasta su fallecimiento. Unos años después recibió la trasmisión del Dharma del maestro Kosen Thibaut, also disciple de Dešimarou, convirtiéndose así en la primera maester Zen europea. Bárbara es, por tanto, el último eslabón de una cadena de trasmisiones que remonta a 2.500 años. 5.4.- La ordenación. Se llama shanga a conjunto de estudiantes en torno a un maestro, maestro en nuestro caso. En la sanga hay laicos, bodhittsavas y monjes. En este shanga, la enseñanza es igual para los laicos, bodhittsavas y monjes. 5.5.- Shorin Ji. Shoren Ji is el nombre del templo que la asociación Zen Taisen Deshimaru fundó en el 2001 en la sierra de Gredos. Su traducido nombre: Bosque del Despertar, se refiere al despertar del Buda, a su Iluminación. En Shorin Ji hay tres actividades relacionadas con la práctica: zazen, samu y la costura, aparto de comidas y tiempos de descanso. Zazen se practica al amanecer y al atardecer. El samu son trabajos que se realiza para la comunidad como cocinar, argar el huerto, construir un muro de stone, partir leña o veña para saber qué. El día Hosan es el día de reposo, y esta la ritmo en un día normal del templo. Periódicamente se organizan en Shorin Ji, días de samu y sesshines. La traducción de seshin es “tocar el espíritu”, se refiere al espíritu del Buda. Es un periodo de uno a varios days de vida colectiva, de concentración. Se hacen de cinco a siete horas de zazen por día; también hay un samu muy organizado, comidas y periodos de descanso. 5.6.- Mokusan dojo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_full_text(text):\n",
    "    display(Markdown(text))\n",
    "\n",
    "show_full_text(summarized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- facebook/bart-large-cnn (english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the translation models and summarization model\n",
    "translator_es_en = pipeline(\"translation_es_to_en\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "translator_en_es = pipeline(\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Load tokenizer for chunking\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Function to split the text into smaller chunks using the tokenizer\n",
    "def chunk_text(text, tokenizer, max_length=512):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=max_length)\n",
    "    tokens = inputs['input_ids'].squeeze()\n",
    "    chunks = [tokens[i:i + max_length] for i in range(0, len(tokens), max_length)]\n",
    "    return [tokenizer.decode(chunk, skip_special_tokens=True) for chunk in chunks]\n",
    "\n",
    "# Function to summarize the text\n",
    "def summarize_text(text):\n",
    "    # Translate the text into English\n",
    "    translated_text_chunks = chunk_text(text, tokenizer)\n",
    "    translated_text = \"\"\n",
    "\n",
    "    for chunk in translated_text_chunks:\n",
    "        translated_text += translator_es_en(chunk)[0]['translation_text'] + \" \"\n",
    "\n",
    "    # Split the translated text into smaller chunks if it's too long\n",
    "    text_chunks = chunk_text(translated_text.strip(), tokenizer)\n",
    "\n",
    "    # Generate the summary for each part of the text\n",
    "    summary = \"\"\n",
    "    for chunk in text_chunks:\n",
    "        input_length = len(chunk.split())\n",
    "        dynamic_max_length = min(max(30, int(input_length * 0.5)), 150)  # Adjust the multiplier as needed\n",
    "        summary_result = summarizer(chunk, max_length=dynamic_max_length, min_length=30, do_sample=False)\n",
    "        summary += summary_result[0]['summary_text'] + \" \"\n",
    "\n",
    "    # Translate the summary back into Spanish\n",
    "    final_summary_chunks = chunk_text(summary.strip(), tokenizer)\n",
    "    final_summary = \"\"\n",
    "\n",
    "    for chunk in final_summary_chunks:\n",
    "        final_summary += translator_en_es(chunk)[0]['translation_text'] + \" \"\n",
    "\n",
    "    return final_summary.strip()\n",
    "\n",
    "# Call the English model\n",
    "summarized_text = summarize_text(video_text)\n",
    "print(f\"Resumen:\\n{summarized_text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- t5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Cargar el modelo y el tokenizer\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt5-large\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Puedes probar con 't5-base' o 'mt5-base'\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mT5ForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m T5Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Función para dividir el texto en fragmentos usando el tokenizador\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:3960\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3951\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3953\u001b[0m     (\n\u001b[0;32m   3954\u001b[0m         model,\n\u001b[0;32m   3955\u001b[0m         missing_keys,\n\u001b[0;32m   3956\u001b[0m         unexpected_keys,\n\u001b[0;32m   3957\u001b[0m         mismatched_keys,\n\u001b[0;32m   3958\u001b[0m         offload_index,\n\u001b[0;32m   3959\u001b[0m         error_msgs,\n\u001b[1;32m-> 3960\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3967\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgguf_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[0;32m   3980\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:4255\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules, gguf_path)\u001b[0m\n\u001b[0;32m   4253\u001b[0m             model\u001b[38;5;241m.\u001b[39mapply(model\u001b[38;5;241m.\u001b[39m_initialize_weights)\n\u001b[0;32m   4254\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4255\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4257\u001b[0m \u001b[38;5;66;03m# Set some modules to fp32 if any\u001b[39;00m\n\u001b[0;32m   4258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_in_fp32_modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:896\u001b[0m, in \u001b[0;36mModule.apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m    895\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[1;32m--> 896\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\modeling_utils.py:1819\u001b[0m, in \u001b[0;36mPreTrainedModel._initialize_weights\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m   1817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_hf_initialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m-> 1819\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1820\u001b[0m module\u001b[38;5;241m.\u001b[39m_is_hf_initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:821\u001b[0m, in \u001b[0;36mT5PreTrainedModel._init_weights\u001b[1;34m(self, module)\u001b[0m\n\u001b[0;32m    814\u001b[0m     module\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill_(factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    816\u001b[0m     module,\n\u001b[0;32m    817\u001b[0m     (T5Model, T5ForConditionalGeneration, T5EncoderModel, T5ForQuestionAnswering),\n\u001b[0;32m    818\u001b[0m ):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;66;03m# Mesh TensorFlow embeddings initialization\u001b[39;00m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L1624\u001b[39;00m\n\u001b[1;32m--> 821\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfactor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlm_head\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtie_word_embeddings:\n\u001b[0;32m    823\u001b[0m         module\u001b[38;5;241m.\u001b[39mlm_head\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnormal_(mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, std\u001b[38;5;241m=\u001b[39mfactor \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cargar el modelo y el tokenizer\n",
    "model_name = 't5-large'  # Puedes probar con 't5-base' o 'mt5-base'\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Función para dividir el texto en fragmentos usando el tokenizador\n",
    "def chunk_text(text, tokenizer, max_length=512):\n",
    "    tokens = tokenizer.encode(text, return_tensors=\"pt\").squeeze()\n",
    "    chunks = [tokens[i:i + max_length] for i in range(0, len(tokens), max_length)]\n",
    "    return [tokenizer.decode(chunk, skip_special_tokens=True) for chunk in chunks]\n",
    "\n",
    "# Resumir el texto\n",
    "def summarize_t5(text, tokenizer, model, max_length=512, min_length=100):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
    "    summary_ids = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        length_penalty=1.5,\n",
    "        num_beams=6,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Fragmentar el texto y generar resúmenes parciales\n",
    "chunks = chunk_text(video_text, tokenizer, max_length=512)\n",
    "summaries = [summarize_t5(chunk, tokenizer, model) for chunk in chunks]\n",
    "final_summary = \" \".join(summaries)\n",
    "\n",
    "#print(final_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "from transformers import MarianMTModel, MarianTokenizer, pipeline\n",
    "from IPython.display import display, Markdown\n",
    "from langdetect import detect\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the text_generated\n",
    "folder_path = 'processed_data'\n",
    "#file_path = os.path.join(folder_path, 'web_scrapping_text.txt'), encoding='utf-8'\n",
    "file_path = os.path.join(folder_path, 'pdf_pymu_text.txt')\n",
    "#file_path = os.path.join(folder_path, 'video_text.txt')\n",
    "\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    video_text = file.read()\n",
    "\n",
    "#print(video_text)\n",
    "#print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "class MultilingualSummarizer:\n",
    "    def __init__(self, model_name='facebook/mbart-large-50-many-to-many-mmt'):\n",
    "        self.tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
    "        self.model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    def summarize(self, text, source_lang='en_XX', target_lang='es_XX', max_length=512, num_beams=5, length_penalty=1.5, no_repeat_ngram_size=2):\n",
    "        self.tokenizer.src_lang = source_lang\n",
    "        forced_bos_token_id = self.tokenizer.lang_code_to_id[target_lang]\n",
    "\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "        summary_ids = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            forced_bos_token_id=forced_bos_token_id,\n",
    "            num_beams=num_beams,\n",
    "            length_penalty=length_penalty,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Eliminar música, menciones irrelevantes y otros ruidos\n",
    "    clean_text = re.sub(r'\\[Música\\].*?Compartir', '', text, flags=re.DOTALL).strip()\n",
    "    return clean_text\n",
    "\n",
    "# Uso en el código\n",
    "input_text = preprocess_text(video_text)\n",
    "summarized_text = summarizer.summarize(input_text, source_lang='en_XX', target_lang='es_XX')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El Presidente (habla en inglés): El Consejo de Seguridad comenzará ahora el examen del tema que figura en el orden del día."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_full_text(text):\n",
    "    display(Markdown(text))\n",
    "\n",
    "show_full_text(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multilingual transformer\n",
    "class MultilingualSummarizer:\n",
    "    def __init__(self, model_name='facebook/mbart-large-50-many-to-many-mmt'):\n",
    "        # Initialize the tokenizer and the mBART model.\n",
    "        self.tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
    "        self.model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    def summarize(self, text , source_lang='en_XX', target_lang='es_XX', max_length=512):\n",
    "        # Set the source and target languages\n",
    "        self.tokenizer.src_lang = source_lang\n",
    "        forced_bos_token_id = self.tokenizer.lang_code_to_id[target_lang]\n",
    "\n",
    "        # Tokenize the input text.\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "        # Generate the summary\n",
    "        summary_ids = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            forced_bos_token_id=forced_bos_token_id,\n",
    "            num_beams=4,\n",
    "            length_penalty=2.0,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "\n",
    "        # Decode the summary.\n",
    "        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "\n",
    "\n",
    "#Call the multilingual transformer\n",
    "if __name__ == \"__main__\":\n",
    "    # Input text\n",
    "    input_text = video_text \n",
    "\n",
    "     # Detect the language of the input text\n",
    "    detected_language = detect(input_text)\n",
    "    source_lang = {\n",
    "        'en': 'en_XX',\n",
    "        'es': 'es_XX',\n",
    "        # Add more language mappings as needed\n",
    "    }.get(detected_language, 'en_XX')  # Default to English if detection fails\n",
    "\n",
    "\n",
    "    # Create an instance of the multilingual summary\n",
    "    summarizer = MultilingualSummarizer()\n",
    "\n",
    "    # Generate a summary in Spanish (target_lang='es') from a text in English (source_lang='en')\n",
    "    summarized_text = summarizer.summarize(input_text, source_lang=source_lang, target_lang='es_XX')\n",
    "\n",
    "    #print(f\"Resumen:\\n{summarized_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualSummarizer:\n",
    "    def __init__(self, model_name='facebook/mbart-large-50-many-to-many-mmt'):\n",
    "        # Initialize the tokenizer and the mBART model.\n",
    "        self.tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
    "        self.model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "    def summarize(self, text, source_lang='en_XX', target_lang='es_XX', max_length=512, num_beams=4, length_penalty=2.0, no_repeat_ngram_size=3):\n",
    "        # Set the source and target languages\n",
    "        self.tokenizer.src_lang = source_lang\n",
    "        forced_bos_token_id = self.tokenizer.lang_code_to_id[target_lang]\n",
    "\n",
    "        # Tokenize the input text.\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "        # Generate the summary\n",
    "        summary_ids = self.model.generate(\n",
    "            **inputs,\n",
    "            max_length=max_length,\n",
    "            forced_bos_token_id=forced_bos_token_id,\n",
    "            num_beams=num_beams,\n",
    "            length_penalty=length_penalty,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            early_stopping=True  # Optional: Add this parameter if needed\n",
    "        )\n",
    "\n",
    "        # Decode the summary.\n",
    "        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    \n",
    "#Call the multilingual transformer\n",
    "if __name__ == \"__main__\":\n",
    "    # Input text\n",
    "    input_text = video_text \n",
    "\n",
    "     # Detect the language of the input text\n",
    "    detected_language = detect(input_text)\n",
    "    source_lang = {\n",
    "        'en': 'en_XX',\n",
    "        'es': 'es_XX',\n",
    "        # Add more language mappings as needed\n",
    "    }.get(detected_language, 'en_XX')  # Default to English if detection fails\n",
    "\n",
    "\n",
    "    # Create an instance of the multilingual summary\n",
    "    summarizer = MultilingualSummarizer()\n",
    "\n",
    "    # Generate a summary in Spanish (target_lang='es') from a text in English (source_lang='en')\n",
    "    summarized_text = summarizer.summarize(input_text, source_lang=source_lang, target_lang='es_XX')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El Presidente (habla en inglés): Doy las gracias al Secretario General por haber convocado esta sesión."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_full_text(text):\n",
    "    display(Markdown(text))\n",
    "\n",
    "show_full_text(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summary\n",
    "with open(os.path.join('output_data', 'summary_multilingual_model.txt'), 'w') as file:\n",
    "    file.write(summarized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENGLISH SUMMARIZER WITH TRANSLATION PIPELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English transformer + pipelines to translate text to english\n",
    "\n",
    "# Load the Spanish to English translation model.\n",
    "translator_es_en = pipeline(\"translation_es_to_en\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "\n",
    "# Load the English to Spanish translation model.\n",
    "translator_en_es = pipeline(\"translation_en_to_es\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
    "\n",
    "# Load the English summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Function to split the text into smaller chunks.\n",
    "def chunk_text(text, max_length=512):\n",
    "    tokens = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for token in tokens:\n",
    "        if current_length + len(token) + 1 > max_length:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [token]\n",
    "            current_length = len(token)\n",
    "        else:\n",
    "            current_chunk.append(token)\n",
    "            current_length += len(token) + 1\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Function to summarize the text.\n",
    "def summarize_text(text):\n",
    "    # Translate the text into English\n",
    "    translated_text_chunks = chunk_text(text)\n",
    "    translated_text = \"\"\n",
    "\n",
    "    for chunk in translated_text_chunks:\n",
    "        translated_text += translator_es_en(chunk, max_length=512)[0]['translation_text'] + \" \"\n",
    "\n",
    "    # Split the translated text into smaller chunks if it's too long\n",
    "    text_chunks = chunk_text(translated_text.strip(), max_length=512)\n",
    "\n",
    "    # Generate the summary for each part of the text\n",
    "    summary = \"\"\n",
    "    for chunk in text_chunks:\n",
    "        # Calculate max_length dynamically.\n",
    "        input_length = len(chunk.split())\n",
    "        dynamic_max_length = min(max(30, int(input_length * 0.5)), 150)  # Adjust the multiplier 0.5 as needed.\n",
    "        summary_result = summarizer(chunk, max_length=dynamic_max_length, min_length=30, do_sample=False)\n",
    "        summary += summary_result[0]['summary_text'] + \" \"\n",
    "\n",
    "    # Translate the summary back into Spanish.\n",
    "    final_summary_chunks = chunk_text(summary.strip(), max_length=512)\n",
    "    final_summary = \"\"\n",
    "\n",
    "    for chunk in final_summary_chunks:\n",
    "        final_summary += translator_en_es(chunk, max_length=512)[0]['translation_text'] + \" \"\n",
    "\n",
    "    return final_summary.strip()\n",
    "\n",
    "# Call the english model\n",
    "summarized_text = summarize_text(video_text)\n",
    "#print(f\"Resumen:\\n{summarized_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "El condado de Miami-Dade tiene una de las poblaciones más concentradas de la nación de haitianos. De los 2.7 millones de residentes del condado, alrededor del 3,7% son Hait Tump y Vances han extendido los edificios municipales envejecidos en Springfield, Ohio. Las amenazas se desenvolvieron a raíz de las demandas salvajes y completamente infundadas de los defensores de los inmigrantes. \"Los archivos y las conspiraciones sobre los haitianos son parte de un gran volumen de retórica antiinmigrante y deshumanizante\", dijo Alicia Victoria Lozano, reportera de NBC News con sede en California. Se centra en el cambio climático, los incendios forestales y la cambiante política de las leyes de drogas. \"Están escuchando el mensaje de Trump Ezra Frechled un golpe lento en todo el estadio el martes durante su evento de marquesina, el salto alto. Su récord de 1,94 metros de altura fue un récord para el entrenador de Frech, Roderick Townsend, Nick Mayhugh dejó salir un bullicioso “LET’ Más de 2 millones de entradas se han vendido para los Juegos Paralímpicos. Más personas están viendo desde casa, Nielsen datos del 28 de agosto al sábado shows. Viendo desde casa un promedio de 231.000 espectadores a través de Peacock, NBC, USA Network y CNBC. Eso es un aumento del 125% de los Paralímpicos de Tokio. Avideo Team Estados Unidos Bill Hamiter dijo que los tres equipos en esa energía. Lo mismo va para American Ian Seidenfeld en Para el tenis de mesa. Los aficionados se tiraron su feed en los blasters en un desarrollo Durante el fútbol ciego, la multitud todavía está para permitir a los jugadores parados visualmente para escuchar el balón de fútbol. Douglass dijo que se sorprendió por el Grado de Emoción. en los Paralímpicos El Vision Pad mueve la pelota en tiempo real para reflejar la acción de campo y vibradores durante momentos emocionantes. Charles E. Catherine-Caldaro, un miembro del U.S. Már Gunnarsson es un atleta paralímpico abiertamente gay. Los Angeles Summer Games en 2028. “Es el nadador islandés Gunnarsson también es un músico profesional, un estudiante y un defensor de los derechos de las personas paradas visualmente. “Pienso para mí, ‘Si quisiera escoger una cosa, Gunnarson es uno de los pocos nadadores LGBTQ que alguna vez competirán en los Paralímpicos. Se clasificó para la final de 100 metros de retroceso y terminó en siete lugares. Gunnarsson mencionó ser gay en medio de una entrevista que rápidamente se volvió viral en su país de origen. Gunnarsson es también un cantante y pianista. Divide su tiempo entre Islandia, Luxemburgo y el Reino Unido. Actualmente está trabajando en un álbum, Una canción del álbum, “Spirit in Motion”, fue lanzado en agosto durante las dos semanas entre los Juegos Olímpicos y Paralímpicos. Gunnarsson fue anfitrión de la canción podría puentear el nadador islandés Gunnarsson dice que los olímpicos y los paralímpicos deberían mezclarse. “Podríamos aprender mucho unos de otros y construir un fuerte Si nos gustaría Gunnarsson es un estudiante en el Reino Unido, donde no es capaz de volar con su perro guía, Max. Su crítica pública de las regulaciones son una extensión de la defensa de los derechos de los discapacitados que él “me parece tan importante no importa quiénes somos o en qué posición estamos en ... cuando vamos a los Juegos Olímpicos o Paralímpicos, siempre deberíamos simplemente venir a la puerta como estamos, atleta transgénero italiana Valentina Petrillo no llegó a la final de los 400m de mujeres. Petrillo estaba trabajando en público Petrillo, de 50 años de edad, tuvo un mejor rendimiento personal de 57,58 segundos en la segunda semifinal. El iraní Hajar Safarzadeh Ghahder Petrillo tiene una enfermedad de la retina que causa una pérdida progresiva de visión. Su sueño de competir fue provocado por el atleta italiano Pietro Mennea, la gimnasta estadounidense Jordan Chiles, de 200 metros de oro, ha apelado a la corte suprema de Suiza para reclamar su bronce durante la final de ejercicios de suelo femenino en París. Chiles se trasladó al tercer lugar y obtuvo el bronce después de desafiar la puntuación de los jueces por uno de los elementos en su ruta. Sin embargo, fue trasladada a los cinco días después de que Chiles alegara que la decisión de CAS violaba las cuestiones de procedimiento, específicamente el “derecho a ser oído” de Chiles. También alega un conflicto de intereses, ya que Hamid G Chiles ganó un equipo de oro en París después de ganar un equipo de plata en Tokio en 2021. “Lo más importante que me quitaron fue el reconocimiento de quién era”, Chiles Los jefes están expuestos a colocarlo en la reserva lesionada. Pacheco fue herido en la victoria 26-25 de Kansas City sobre el Cincinnati Bengals en Pacheco, 25, está en su tercer año con los jefes. En 14 partidos el año pasado, corrió 935 yardas y siete touchdowns. También tomó 44 pasos para 244. Los jefes traerán a Kareem Hunt para una visita el martes. Clyde Edwards-Helaire está fuera al menos la semana 5 después de que comenzó la temporada en la lista de lesiones no de fútbol. Son 2-0 después de su victoria sobre los Bengals. Ellos jugarán los Atlanta Falcons en \"Sunday Night Football\" en la semana 3. fue drenado por Kansas City en 2017 y apareció en 27 partidos para el equipo Bryce Young, la selección número 1 en el draft de la NFL 2023, será reemplazado por Andy Dalton. El entrenador de Carolina Dave Canales endosó a Young como \"nuestro quarterback\" después de que los Panthers' Channels fue una selección superior después de una carrera estelarcollege en Alabama. Ha luchado para subir su juego los domingos. El jugador de 37 años había sido el quarterback de Cincinnati durante mucho tiempo, llevando a los bengalíes a los playoffs cuatro veces y al principio del Pro Bowl honra tres veces. Desde que salió de los bengalíes antes de la temporada 2020 \"Estaba seguro de si iba a empezar de nuevo\", dijo Dalton a los miembros de los medios el lunes. Ha comenzado en solo 30 partidos con cuatro equipos durante un poco más de cuatro temporadas. Target acaba de anunciar su próxima Semana del Círculo Target. Durante este evento, los miembros pueden ahorrar en Los miembros de Target Circle pueden desbloquear ofertas y juegos personalizados para usted y sus hábitos de compra. Usted también puede lanzar a la comunidad. Los miembros de Target Circle pueden desbloquear ofertas y juegos personalizados para usted y sus hábitos de compra. apoyo votos para ayudar al minorista a elegir honorarios para donar. Bianca Alvarez es una reportera asociada en NBC Select. Ella ha cubierto ofertas y sales durante más de un año, incluyendo Target Circle Week y Amazon Prime Day. Los 100 mejores hidratantes valorados, como probados por NBC Select editores. Cuidado de la piel Cuidado del cabello Cuidado Oral Salud Fitness Electrodomésticos de la cocina del sueño y herramientas Small Home Electrodomésticos Los dermatólogos están de acuerdo en que los hidratantes son un componente crítico de cualquier ruta diaria del cuidado de la piel. Para su tipo de piel, textura y edad puede tomar un poco de prueba y error. NBC Select probó más de 135 fórmulas durante casi cinco meses y valoró nuestro top 100. La lista se basa en una compilación de nuestro informe anterior sobre las mejores cremas hidratantes para kinandmature seco Nuestro equipo presentó nominaciones para productos que querían poner a prueba. Nos centramos en cremas de día y de noche, y fórmulas excluidas con AHAs o BHAs. Consideramos marcas de farmacia, como Cerave y Cetaphil, con tanto pensamiento y cuidado como más opciones rápidas de marcas como SkinCeuticals y Bioss Nuestro equipo probó más de 135 hidratantes durante cuatro meses. Al menos dos editores probaron cada producto. Cada entrada podría ganar un máximo de tres puntos por categoría. Después de utilizar datos cuantitativos para obtener un rango inicial basado en puntuaciones medias, añadimos la colocación de ciertos hidratantes basados en notas del editor, disponibilidad y punto de precio. Tratamos de incluir sólo once de la marca en Neutrogena Hydro Boost Hyaluronic Acid Moisturizer SPF 50 98:Monika Derma E Vitamina C Renovando Moisturizador 87:Rhode Barrera Restauración Crema 86:Jackfir El clásico diario Facial Retrouvé Replencing Intensivo Hidratante Facial 75. SkinMedica Dermal Repair Cream 73. Domingo Riley C Farmacy Daily Greens Aceite Gel Hidratante Cara Libre 65:Lanolips 101 Skin Dry Super Cream 64:Thayers Let’s Be Lancer Skincare The Method: Nutrish Women’s Anti-Aging Moisturizer 47:Byoma Mo 40:Farmacy Honey Halo Ceramida Face Moisturizer Cream 39:Innisfree Green Tea Crema Hyalurónica de Semillas 38:Piel por Me encanta este embalaje amarillo vibrador, siempre llama mi atención de inmediato en mi armario. Tengo piel seca, sensible y propensa a la androsácea. Esta es una gran opción sin fragancias que uso explícitamente por la mañana. Me gusta que tenga una textura súper ligera, muy similar a la que absorbe rápidamente mi piel. Es cierto que la crema ligera de Dermalogica fue ideal para mi piel combinada. En invierno, mi cara frijol hueso seco — como esa escena en “SpongeBob SquarePants’ Mejor para: piel seca, combinación. podría haber sido un poco demasiado ligero para mi piel. Me di cuenta de que algunas veces se secaría después de sólo unas horas, por lo que no se clasifica excursionista Es ligero y fácil de aplicar. Oclusivo, lo que significa que se encuentra sobre la piel y actúa como barredora. Sólo lo uso cuando se trata de piel muy seca. El embalaje vibratorio fue lo primero que noté acerca de este hidratante. Esta bomba era más controlado que otros que he probado, pero todavía me cave un poco demasiado producto. tiene una textura ligera, casi de aire que se extiende fácilmente a través de mi piel con cero sensaciones de calor. A pesar de su sensación ligera, los niveles de humedad de mi piel duraron todo el día. Esta crema es extremadamente hidratante. Absorbe al instante y no se siente pesado. También es descentrado, que es algo que tiendo a buscar en la crema facial. Esta hidratante es simple pero todavía consigue el trabajo hecho. Tiene todos los ingredientes que quiero en una crema de reparación de barrio. A diferencia de otras opciones, tiene una consistencia ligera. Mieczemaflare-ups tienen menos enrojecimiento e irritación. No ocupa mucho espacio en mis bolsas, tampoco. Como tengo la piel seca, tiendo a pasar por la hidratación Es una de las pocas cremas hidratantes que he intentado que me encontré para ser actualmente libre de fragancias. En general, es una crema hidratante confiable, pero no usaría El centro es suave, que me gusta como alguien que no quiere utilizar una crema facial que pequeña como una loción de fragante mano. Sólo necesitaba una montura pequeña para cubrir mi cara (The Water Lock Moisturizer de Tata Harper Su tapa de oro brillante, contenedor redondeado y el dispensador de estilo bomba sin aire son Es un buen hidratante para las personas con piel dorada combinación, y tiene un té verde luminoso pero sutil en el centro. Desde un punto de vista práctico, la forma cilíndrica corta se ajusta muy bien Vanicurem Daily hidratante está en el lado de la etiqueta pero no registrar poros. Este es uno de los pocos productos en los EE.UU. que vienen en la bañera motorista Una de las cosas que más me encanta de esta crema es que actualmente no es mucho de una crema en absoluto. Es tan ligero que se siente mucho más como mucho, especialmente teniendo en cuenta cómo la mejor crema hidratante tiene un acabado ligeramente rocío. La crema absorbido tan rápidamente en mi piel que podría aplicar mi protector solar casi inmediatamente después. En los días más calientes que tiende a ponerse ligeramente gris cuando Olay Microsculpting Cream se hace con ácido láctico. Revisor notó más brillante, más uniforme tono de la piel después de usarlo once veces. Para los con rosácea y eczema Cerave El hidratante es delgado y ligero sin sentir agua. El envase de la bañera le permite tomar justo lo que necesita y fácil ponerlo de nuevo cualquier exceso. Está libre de irritantes comunes (como fragancias añadidas) y tiene el Sello de Aceptación de la Asociación Nacional de Eczema. Un poco va tan lejos, por lo que una bañera dura Ceramidas, ácido hialurónico, gasolinatum son ingredientes clave. La crema es cremosa y absorbe rápidamente sin sentirse grasiento o pesado en la piel. Belif True Cream Aqua Bomb es un reciente NBC Select Ganador del premio Wellness. Lo mejor para:normal, seco, combinación y piel de aceites Ingredientes clave: harina coloidal del océano, glicerina Es ligero, por lo que me sorprendió lo eficaz que era. Especifiqué para mezclar en mi cara sin mucho cambio notable, pero funcionó inmediatamente. Mi piel se sintió repuesta y me mantuve Como alguien con aceite y piel de combinación, a veces estrangulo para encontrar una buena crema en general. Generalmente hago compras en Sephora y experimento con varias cremas hidratantes de marca. Me sorprendió por Biossance gel humectante es uno de los pocos que no me causó ningún quiebre o irritación. Es una fórmula que sigo volviendo en el medio de probar otras opciones como una manera de Genuinely sin fragancia, que aprecio y tienen un efecto de enfriamiento instantáneo que se siente removido en la piel. Tiene consistencia Goldilocks de esefecto, también — es Tolerane doble reparación cara de La Roche-Posay hidratante cumple con todos mis requisitos. No tiene un olor y se absorbe en mi piel rápidamente por lo que I The Glossier After Baume es 1.35 oz., 3.38 oz. Mejor para: piel sensible, seca, normal y combinada. Ingredientes clave:ceramidas, Bajo esta tapa verde brillante es una hidratante que puede manejar cualquier y todo. Como una punta profesional, explorar el producto fuera de la lata y calentarlo en sus manos. Cetaphil se siente garrapata y rico como sale del frasco, con un aroma apenas registra en mi nariz. Todos en nuestro personal que probó esto lo encontró simple, confiable y nutritivo. Niacinamida, glicerina, vaselina de petróleo están entre los ingredientes en este hidratante paquete. Para este paquete, nuestro personal probó 135 + hidratantes de cara sobre Consideramos popular marca de farmacia, así como las opciones más vendidas de las marcas de gama alta. Calificamos nuestros mejores concursos y pedimos a los lectores que voten por su favorito. 57 + mejores ventas para comprar esta semana para beding, baño, ropa y más. Otoño está a la vuelta de la esquina, y las marcas están ofreciendo descuentos. Ahorre en comodidades esenciales comorobes, camas y más deParachute. Seleccione tiene una selección de bestsellers y ventas. Algunos artículos pueden tener una oferta de tiempo limitado. Desplácese hacia abajo para ver la lista completa de ventas. CALPAK $25.00 $54.95 American Eagle $80.00 Adidas $230.00 The North Face $32.50 Ashley Morris es una reportera asociada de SEO para Select on NBC News. Para encontrar las mejores ventas cada semana, reúno ofertas y sales de minoristas a través de la web. Nectar La membresía de Sam Club está a la venta por $15: Lo que necesita saber Skin Care Hair Care Oral Care Health Fitness Sleep Kitchen Electrodomésticos & Herramientas Electrodomésticos pequeños Bedd hasta el 27 de septiembre, los no miembros pueden obtener una membresía Club de un año de duración por sólo $15. Los miembros actuales pueden obtener beneficios adicionales hasta el 30 de septiembre. La membresía Club Plus de Sam viene con beneficios adicionales y está a la venta hasta el 27 de septiembre. También obtiene beneficios como ofertas y ventas de sólo miembros, entrega del mismo día y descuentos en los miembros del Club obtener entrega gratuita desde el Club o envío gratuito en pedidos elegibles de $50 o más. Con un. el más actualizado por $50 para el año, los más Los miembros actuales del club y Plus pueden obtener beneficios adicionales hasta el 30 de septiembre. Usted también tiene acceso al minorista La membresía del club normalmente cuesta $50, pero actualmente está a la venta por $15 para los no miembros hasta el 27 de septiembre. La membresía del club de Sam Plus es por lo general $110 por un año Cuando usted se inscribe para una membresía básica del club de Sam, ahora $15 (70% de descuento) para los no miembros hasta el 27 de septiembre. Con esta membresía anual (regularmente $50), los miembros actuales del club de Sam pueden obtener La membresía anual está a la venta por $50 para los no-miembros hasta el 27 de septiembre. Alto a 5 pies y 5 pulgadas con ojos LED. incluye dos músicos esqueleto interactivos en espera. Estos maestros activados por movimiento también tocan un dúo de jazz estropeado. Las tapas son intercambiables a través de las cajas, por lo que no tienes que preocuparte de emparejarlos para encontrar el ajuste adecuado. También tiene un fresco-a-la-las 24 onzas vaso tienen aislamiento de vacío de doble pared, que mantiene las bebidas calientes caliente, El tumb Los leggings están hechos de tejido elástico de cuatro vías que es UPF 50. Están disponibles en ocho colores neutros, como Soft Silver, Zinc o Washed Indigo Ambas bolsas tienen una cáscara exterior resistente a los arañazos y vienen en cinco colores. Las maletas también tienen ruedas de nieve duales y cerraduras combinadas TSA. Dentro de la bolsa de mano, hay un Lauren Levy ha escrito para CNN Underscored, Yahoo Entertainment, MSN, USA Today y más. Para esta historia, ella investigó el diferente Sam's Club The Knot se ha asociado con Care.com para ayudarle con la planificación de su boda. Lea la historia completa aquí. Para más información,"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_full_text(text):\n",
    "    display(Markdown(text))\n",
    "\n",
    "show_full_text(summarized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the summary\n",
    "with open(os.path.join('output_data', 'summary_english_model.txt'), 'w') as file:\n",
    "    file.write(summarized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T5 (Text-to-Text Transfer Transformer) MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual de iniciación y aprendizaje de zazen. a la meditación Zen la llamamos zazen, za: sentarse, zen: concentración. zazen es una práctica. 4.1.- El pensamiento Shiryo, Fushiryo e Hishiryo. 4.2.- La conciencia Mana, Alaya y Amal\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Cargar el modelo y el tokenizer\n",
    "model_name = 't5-base'  # También puedes probar 't5-large' o 'mt5-base' para multilingüe\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Resumir el texto\n",
    "def summarize_t5(text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=500, min_length=100, length_penalty=3.0, num_beams=6, early_stopping=False)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "summarized_text = summarize_t5(video_text)\n",
    "print(summarized_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------ dividiendolo en chunks--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Fragmentar el texto y generar resúmenes parciales\u001b[39;00m\n\u001b[0;32m     19\u001b[0m chunks \u001b[38;5;241m=\u001b[39m chunk_text(video_text, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m summaries \u001b[38;5;241m=\u001b[39m [summarize_t5(chunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     21\u001b[0m final_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(summaries)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#print(final_summary)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 20\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Fragmentar el texto y generar resúmenes parciales\u001b[39;00m\n\u001b[0;32m     19\u001b[0m chunks \u001b[38;5;241m=\u001b[39m chunk_text(video_text, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m summaries \u001b[38;5;241m=\u001b[39m [\u001b[43msummarize_t5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     21\u001b[0m final_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(summaries)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#print(final_summary)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m, in \u001b[0;36msummarize_t5\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msummarize_t5\u001b[39m(text):\n\u001b[0;32m     14\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarize: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 15\u001b[0m     summary_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mdecode(summary_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:2063\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2055\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2056\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m   2057\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   2058\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2059\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2060\u001b[0m     )\n\u001b[0;32m   2062\u001b[0m     \u001b[38;5;66;03m# 14. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2063\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_beam_search(\n\u001b[0;32m   2064\u001b[0m         input_ids,\n\u001b[0;32m   2065\u001b[0m         beam_scorer,\n\u001b[0;32m   2066\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mprepared_logits_processor,\n\u001b[0;32m   2067\u001b[0m         logits_warper\u001b[38;5;241m=\u001b[39mprepared_logits_warper,\n\u001b[0;32m   2068\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mprepared_stopping_criteria,\n\u001b[0;32m   2069\u001b[0m         generation_config\u001b[38;5;241m=\u001b[39mgeneration_config,\n\u001b[0;32m   2070\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   2071\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2072\u001b[0m     )\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2076\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2077\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   2078\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2084\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[0;32m   2085\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\generation\\utils.py:3238\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, logits_warper, **model_kwargs)\u001b[0m\n\u001b[0;32m   3235\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m stack_model_outputs(outputs_per_sub_batch)\n\u001b[0;32m   3237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Unchanged original behavior\u001b[39;00m\n\u001b[1;32m-> 3238\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   3241\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1739\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1736\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[1;32m-> 1739\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1754\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1106\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1091\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1092\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[0;32m   1093\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1103\u001b[0m         output_attentions,\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1106\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:746\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    743\u001b[0m     attention_outputs \u001b[38;5;241m=\u001b[39m attention_outputs \u001b[38;5;241m+\u001b[39m cross_attention_outputs[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m    745\u001b[0m \u001b[38;5;66;03m# Apply Feed Forward layer\u001b[39;00m\n\u001b[1;32m--> 746\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16:\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:335\u001b[0m, in \u001b[0;36mT5LayerFF.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[0;32m    334\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 335\u001b[0m     forwarded_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDenseReluDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforwarded_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(forwarded_states)\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:289\u001b[0m, in \u001b[0;36mT5DenseActDense.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight, torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m hidden_states\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mint8\n\u001b[0;32m    287\u001b[0m ):\n\u001b[0;32m    288\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwo\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 289\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Agustina Torres\\Documents\\DEV\\IMF\\TFM\\SELENIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Cargar el modelo y el tokenizer\n",
    "model_name = 't5-large'  # Puedes probar con 't5-base' o 'mt5-base'\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Función para dividir el texto en fragmentos\n",
    "def chunk_text(text, max_length=512):\n",
    "    return [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "\n",
    "# Resumir el texto\n",
    "def summarize_t5(text):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=500, min_length=200, length_penalty=1.5, num_beams=6, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# Fragmentar el texto y generar resúmenes parciales\n",
    "chunks = chunk_text(video_text, max_length=512)\n",
    "summaries = [summarize_t5(chunk) for chunk in chunks]\n",
    "final_summary = \" \".join(summaries)\n",
    "\n",
    "#print(final_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "manual de iniciación y aprendizaje de zazen. a la meditación Zen la llamamos zazen, za: sentarse, zen: concentración. zazen es una práctica. 4.1.- El pensamiento Shiryo, Fushiryo e Hishiryo. 4.2.- La conciencia Mana, Alaya y Amal"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_full_text(text):\n",
    "    display(Markdown(text))\n",
    "\n",
    "show_full_text(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
